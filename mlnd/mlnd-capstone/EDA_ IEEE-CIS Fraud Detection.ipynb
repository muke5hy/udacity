{"cells":[{"metadata":{},"cell_type":"markdown","source":"## General information\n\n\n\n# Data and Questions\n\n\nIn this competition you are predicting the probability that an online transaction is fraudulent, as denoted by the binary target ```isFraud```.\n\nThe data is broken into two files **identity** and **transaction**, which are joined by ```TransactionID```. \n\n> Note: Not all transactions have corresponding identity information.\n\n**Categorical Features - Transaction**\n\n- ProductCD\n- emaildomain\n- card1 - card6\n- addr1, addr2\n- P_emaildomain\n- R_emaildomain\n- M1 - M9\n\n**Categorical Features - Identity**\n\n- DeviceType\n- DeviceInfo\n- id_12 - id_38\n\n**The TransactionDT feature is a timedelta from a given reference datetime (not an actual timestamp).**\n"},{"metadata":{},"cell_type":"markdown","source":"\n## Questions\nI will start exploring based on Categorical Features and Transaction Amounts.\nThe aim is answer some questions like:\n- What type of data we have on our data?\n- How many cols, rows, missing values we have?\n- Whats the target distribution?\n- What's the Transactions values distribution of fraud and no fraud transactions?\n- We have predominant fraudulent products? \n- What features or target shows some interesting patterns? \n- And a lot of more questions that will raise trought the exploration. \n"},{"metadata":{"trusted":false},"cell_type":"code","source":"import os\nfolder_path = '../input/ieee-fraud-detection/'\nprint(os.listdir(folder_path))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Imports and Functions used in this kernel\nThey are in the hidden cell below."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_kg_hide-input":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nfrom sklearn.svm import NuSVR, SVR\nfrom sklearn.metrics import mean_absolute_error\nimport lightgbm as lgb\nimport xgboost as xgb\nimport time\nimport datetime\nfrom catboost import CatBoostRegressor, CatBoostClassifier\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold, GroupKFold, GridSearchCV, train_test_split, TimeSeriesSplit\nfrom sklearn import metrics\nfrom sklearn import linear_model\nfrom hyperopt import fmin, hp, tpe, Trials, space_eval, STATUS_OK, STATUS_RUNNING\nimport gc\nfrom numba import jit\nimport seaborn as sns\nfrom tqdm import tqdm_notebook\nfrom itertools import product\nfrom IPython.display import HTML\nfrom joblib import Parallel, delayed\nimport matplotlib.pyplot as plt\nimport warnings\nfrom scipy import stats\n\npd.options.display.precision = 15\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline\n\n        \ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data loading and overview\n\nData is separated into two datasets: information about the identity of the customer and transaction information. Not all transactions belong to identities, which are available. Maybe it would be possible to use additional transactions to generate new features."},{"metadata":{"trusted":false},"cell_type":"code","source":"%%time \ntrain_transaction = pd.read_csv(f'{folder_path}train_transaction.csv')\ntrain_identity = pd.read_csv(f'{folder_path}train_identity.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"%%time \n\ntrain_transaction = reduce_mem_usage(train_transaction)\ntrain_identity = reduce_mem_usage(train_identity)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(\"train_transaction\",train_transaction.shape)\nprint(\"train_identity\",train_identity.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So we have two medium-sized datasets with a lot of columns. Train and test data have similar number of rows"},{"metadata":{"trusted":false},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory data analysis (EDA)"},{"metadata":{"trusted":false},"cell_type":"code","source":"def resumetable(df):\n#     print(f\"Dataset Shape: {df.shape}\")\n    summary = pd.DataFrame(df.dtypes,columns=['dtypes'])\n    summary = summary.reset_index()\n    summary['Name'] = summary['index']\n    summary = summary[['Name','dtypes']]\n    summary['Missing'] = df.isnull().sum().values    \n    summary['Uniques'] = df.nunique().values\n    summary['First Value'] = df.loc[0].values\n    summary['Second Value'] = df.loc[1].values\n    summary['Third Value'] = df.loc[2].values\n\n    for name in summary['Name'].value_counts().index:\n        summary.loc[summary['Name'] == name, 'Entropy'] = round(stats.entropy(df[name].value_counts(normalize=True), base=2),2) \n\n    return summary\n\n\ndef CalcOutliers(df_num): \n\n    # calculating mean and std of the array\n    data_mean, data_std = np.mean(df_num), np.std(df_num)\n\n    # seting the cut line to both higher and lower values\n    # You can change this value\n    cut = data_std * 3\n\n    #Calculating the higher and lower cut values\n    lower, upper = data_mean - cut, data_mean + cut\n\n    # creating an array of lower, higher and total outlier values \n    outliers_lower = [x for x in df_num if x < lower]\n    outliers_higher = [x for x in df_num if x > upper]\n    outliers_total = [x for x in df_num if x < lower or x > upper]\n\n    # array without outlier values\n    outliers_removed = [x for x in df_num if x > lower and x < upper]\n    \n    print('Identified lowest outliers: %d' % len(outliers_lower)) # printing total number of values in lower cut of outliers\n    print('Identified upper outliers: %d' % len(outliers_higher)) # printing total number of values in higher cut of outliers\n    print('Total outlier observations: %d' % len(outliers_total)) # printing total number of values outliers of both sides\n    print('Non-outlier observations: %d' % len(outliers_removed)) # printing total number of non outlier values\n    print(\"Total percentual of Outliers: \", round((len(outliers_total) / len(outliers_removed) )*100, 4)) # Percentual of outliers in points\n    \n    return","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"%%time\n\nresumetable(train_transaction)[:25]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Ploting Transaction Amount Values Distribution"},{"metadata":{"trusted":false},"cell_type":"code","source":"train_transaction['TransactionAmt'] = train_transaction['TransactionAmt'].astype(float)\ntotal = len(train_transaction)\ntotal_amt = train_transaction.groupby(['isFraud'])['TransactionAmt'].sum().sum()\nplt.figure(figsize=(16,6))\n\nplt.subplot(121)\ng = sns.countplot(x='isFraud', data=train_transaction, )\ng.set_title(\"Fraud Transactions Distribution \\n# 0: No Fraud | 1: Fraud #\", fontsize=22)\ng.set_xlabel(\"Is fraud?\", fontsize=18)\ng.set_ylabel('Count', fontsize=18)\nfor p in g.patches:\n    height = p.get_height()\n    g.text(p.get_x()+p.get_width()/2.,\n            height + 3,\n            '{:1.2f}%'.format(height/total*100),\n            ha=\"center\", fontsize=15) \n\nperc_amt = (train_transaction.groupby(['isFraud'])['TransactionAmt'].sum())\nperc_amt = perc_amt.reset_index()\nplt.subplot(122)\ng1 = sns.barplot(x='isFraud', y='TransactionAmt',  dodge=True, data=perc_amt)\ng1.set_title(\"% Total Amount in Transaction Amt \\n# 0: No Fraud | 1: Fraud #\", fontsize=22)\ng1.set_xlabel(\"Is fraud?\", fontsize=18)\ng1.set_ylabel('Total Transaction Amount Scalar', fontsize=18)\nfor p in g1.patches:\n    height = p.get_height()\n    g1.text(p.get_x()+p.get_width()/2.,\n            height + 3,\n            '{:1.2f}%'.format(height/total_amt * 100),\n            ha=\"center\", fontsize=15) \n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Seeing the Quantiles of Fraud and No Fraud Transactions"},{"metadata":{"trusted":false},"cell_type":"code","source":"print(pd.concat([train_transaction[train_transaction['isFraud'] == 1]['TransactionAmt']\\\n                 .quantile([.01, .1, .25, .5, .75, .9, .99])\\\n                 .reset_index(), \n                 train_transaction[train_transaction['isFraud'] == 0]['TransactionAmt']\\\n                 .quantile([.01, .1, .25, .5, .75, .9, .99])\\\n                 .reset_index()],\n                axis=1, keys=['Fraud', \"No Fraud\"]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Transaction Amount Outliers\n- It's considering outlier values that are highest than 3 times the std from the mean"},{"metadata":{"trusted":false},"cell_type":"code","source":"CalcOutliers(train_transaction['TransactionAmt'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If we consider only values between >= 0 to 800 we will avoid the outliers and has more confidence in our distribution. <br>\nWe have 10k rows with outliers that represents 1.74% of total rows."},{"metadata":{},"cell_type":"markdown","source":"### Product Feature\n- Distribution Products\n- Distribution of Frauds by Product\n- Has Difference between Transaction Amounts in Products? "},{"metadata":{"trusted":false},"cell_type":"code","source":"tmp = pd.crosstab(train_transaction['ProductCD'], train_transaction['isFraud'], normalize='index') * 100\ntmp = tmp.reset_index()\ntmp.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n\nplt.figure(figsize=(14,10))\nplt.suptitle('ProductCD Distributions', fontsize=22)\n\nplt.subplot(221)\ng = sns.countplot(x='ProductCD', data=train_transaction)\n# plt.legend(title='Fraud', loc='upper center', labels=['No', 'Yes'])\n\ng.set_title(\"ProductCD Distribution\", fontsize=19)\ng.set_xlabel(\"ProductCD Name\", fontsize=17)\ng.set_ylabel(\"Count\", fontsize=17)\ng.set_ylim(0,500000)\nfor p in g.patches:\n    height = p.get_height()\n    g.text(p.get_x()+p.get_width()/2.,\n            height + 3,\n            '{:1.2f}%'.format(height/total*100),\n            ha=\"center\", fontsize=14) \n\nplt.subplot(222)\ng1 = sns.countplot(x='ProductCD', hue='isFraud', data=train_transaction)\nplt.legend(title='Fraud', loc='best', labels=['No', 'Yes'])\ngt = g1.twinx()\ngt = sns.pointplot(x='ProductCD', y='Fraud', data=tmp, color='black', order=['W', 'H',\"C\", \"S\", \"R\"], legend=False)\ngt.set_ylabel(\"% of Fraud Transactions\", fontsize=16)\n\ng1.set_title(\"Product CD by Target(isFraud)\", fontsize=19)\ng1.set_xlabel(\"ProductCD Name\", fontsize=17)\ng1.set_ylabel(\"Count\", fontsize=17)\n\nplt.subplot(212)\ng3 = sns.boxenplot(x='ProductCD', y='TransactionAmt', hue='isFraud', \n              data=train_transaction[train_transaction['TransactionAmt'] <= 2000] )\ng3.set_title(\"Transaction Amount Distribuition by ProductCD and Target\", fontsize=20)\ng3.set_xlabel(\"ProductCD Name\", fontsize=17)\ng3.set_ylabel(\"Transaction Values\", fontsize=17)\n\nplt.subplots_adjust(hspace = 0.6, top = 0.85)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"W, C and R are the most frequent values.  \nWe can note that in W, H and R the distribution of Fraud values are slightly higher than the Non-Fraud Transactions"},{"metadata":{},"cell_type":"markdown","source":"### Card Features\nBased on Competition Description, card features are categoricals.  \nLets understand the distribution of values  \nWhat's the different in transactions and % of Fraud for each values in these features  \nCard features has 6 columns, and 4 of them seems to be numericals, so lets see the quantiles and distributions  "},{"metadata":{"trusted":false},"cell_type":"code","source":"\n## Knowning the Card Features\nresumetable(train_transaction[['card1', 'card2', 'card3','card4', 'card5', 'card6']])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Card2-Card6 has some missing values. We will need to due with it later."},{"metadata":{},"cell_type":"markdown","source":"#### Numericals Feature Card Quantiles\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"print(\"Card Features Quantiles: \")\nprint(train_transaction[['card1', 'card2', 'card3', 'card5']].quantile([0.01, .025, .1, .25, .5, .75, .975, .99]))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that Card 1 and Card 2 has a large distribution of values, so maybe it will be better to get the log of these columns"},{"metadata":{"trusted":false},"cell_type":"code","source":"\ntrain_transaction.loc[train_transaction.card3.isin(train_transaction.card3.value_counts()[train_transaction.card3.value_counts() < 200].index), 'card3'] = \"Others\"\ntrain_transaction.loc[train_transaction.card5.isin(train_transaction.card5.value_counts()[train_transaction.card5.value_counts() < 300].index), 'card5'] = \"Others\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Visualizing Card 1, Card 2 and Card 3 Distributions\n- As the Card 1 and 2 are numericals, I will plot the distribution of them\n- in Card 3, as we have many values with low frequencies, I decided to set value to \"Others\" \n- Also, in Card 3 I set the % of Fraud ratio in yaxis2"},{"metadata":{"trusted":false},"cell_type":"code","source":"tmp = pd.crosstab(train_transaction['card3'], train_transaction['isFraud'], normalize='index') * 100\ntmp = tmp.reset_index()\ntmp.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n\ntmp2 = pd.crosstab(train_transaction['card5'], train_transaction['isFraud'], normalize='index') * 100\ntmp2 = tmp2.reset_index()\ntmp2.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n\nplt.figure(figsize=(14,22))\n\nplt.subplot(411)\ng = sns.distplot(train_transaction[train_transaction['isFraud'] == 1]['card1'], label='Fraud')\ng = sns.distplot(train_transaction[train_transaction['isFraud'] == 0]['card1'], label='NoFraud')\ng.legend()\ng.set_title(\"Card 1 Values Distribution by Target\", fontsize=20)\ng.set_xlabel(\"Card 1 Values\", fontsize=18)\ng.set_ylabel(\"Probability\", fontsize=18)\n\nplt.subplot(412)\ng1 = sns.distplot(train_transaction[train_transaction['isFraud'] == 1]['card2'].dropna(), label='Fraud')\ng1 = sns.distplot(train_transaction[train_transaction['isFraud'] == 0]['card2'].dropna(), label='NoFraud')\ng1.legend()\ng1.set_title(\"Card 2 Values Distribution by Target\", fontsize=20)\ng1.set_xlabel(\"Card 2 Values\", fontsize=18)\ng1.set_ylabel(\"Probability\", fontsize=18)\n\nplt.subplot(413)\ng2 = sns.countplot(x='card3', data=train_transaction, order=list(tmp.card3.values))\ng22 = g2.twinx()\ngg2 = sns.pointplot(x='card3', y='Fraud', data=tmp, \n                    color='black', order=list(tmp.card3.values))\ngg2.set_ylabel(\"% of Fraud Transactions\", fontsize=16)\ng2.set_title(\"Card 3 Values Distribution and % of Transaction Frauds\", fontsize=20)\ng2.set_xlabel(\"Card 3 Values\", fontsize=18)\ng2.set_ylabel(\"Count\", fontsize=18)\nfor p in g2.patches:\n    height = p.get_height()\n    g2.text(p.get_x()+p.get_width()/2.,\n            height + 25,\n            '{:1.2f}%'.format(height/total*100),\n            ha=\"center\") \n\nplt.subplot(414)\ng3 = sns.countplot(x='card5', data=train_transaction, order=list(tmp2.card5.values))\ng3t = g3.twinx()\ng3t = sns.pointplot(x='card5', y='Fraud', data=tmp2, \n                    color='black', order=list(tmp2.card5.values))\ng3t.set_ylabel(\"% of Fraud Transactions\", fontsize=16)\ng3.set_title(\"Card 5 Values Distribution and % of Transaction Frauds\", fontsize=20)\ng3.set_xticklabels(g3.get_xticklabels(),rotation=90)\ng3.set_xlabel(\"Card 5 Values\", fontsize=18)\ng3.set_ylabel(\"Count\", fontsize=18)\nfor p in g3.patches:\n    height = p.get_height()\n    g3.text(p.get_x()+p.get_width()/2.,\n            height + 3,\n            '{:1.2f}%'.format(height/total*100),\n            ha=\"center\",fontsize=11) \n    \nplt.subplots_adjust(hspace = 0.6, top = 0.85)\n\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cool and Very Meaningful information. <br>\nIn Card3 we can see that 100 and 106 are the most common values in the column. <br>\nWe have 4.95% of Frauds in 100 and 1.52% in 106; The values with highest Fraud Transactions are 185, 119 and 119; <br>\n\nIn card5 the most frequent values are 226, 224, 166 that represents 73% of data. Also is posible to see high % of frauds in 137, 147, 141 that has few entries for values."},{"metadata":{},"cell_type":"markdown","source":"#### Card 4 - Categorical"},{"metadata":{"trusted":false},"cell_type":"code","source":"tmp = pd.crosstab(train_transaction['card4'], train_transaction['isFraud'], normalize='index') * 100\ntmp = tmp.reset_index()\ntmp.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n\nplt.figure(figsize=(14,10))\nplt.suptitle('Card 4 Distributions', fontsize=22)\n\nplt.subplot(221)\ng = sns.countplot(x='card4', data=train_transaction)\n# plt.legend(title='Fraud', loc='upper center', labels=['No', 'Yes'])\ng.set_title(\"Card4 Distribution\", fontsize=19)\ng.set_ylim(0,420000)\ng.set_xlabel(\"Card4 Category Names\", fontsize=17)\ng.set_ylabel(\"Count\", fontsize=17)\nfor p in g.patches:\n    height = p.get_height()\n    g.text(p.get_x()+p.get_width()/2.,\n            height + 3,\n            '{:1.2f}%'.format(height/total*100),\n            ha=\"center\",fontsize=14) \n\n\nplt.subplot(222)\ng1 = sns.countplot(x='card4', hue='isFraud', data=train_transaction)\nplt.legend(title='Fraud', loc='best', labels=['No', 'Yes'])\ngt = g1.twinx()\ngt = sns.pointplot(x='card4', y='Fraud', data=tmp, \n                   color='black', legend=False, \n                   order=['discover', 'mastercard', 'visa', 'american express'])\ngt.set_ylabel(\"% of Fraud Transactions\", fontsize=16)\ng1.set_title(\"Card4 by Target(isFraud)\", fontsize=19)\ng1.set_xlabel(\"Card4 Category Names\", fontsize=17)\ng1.set_ylabel(\"Count\", fontsize=17)\n\nplt.subplot(212)\ng3 = sns.boxenplot(x='card4', y='TransactionAmt', hue='isFraud', \n              data=train_transaction[train_transaction['TransactionAmt'] <= 2000] )\ng3.set_title(\"Card 4 Distribuition by ProductCD and Target\", fontsize=20)\ng3.set_xlabel(\"Card4 Category Names\", fontsize=17)\ng3.set_ylabel(\"Transaction Values\", fontsize=17)\n\nplt.subplots_adjust(hspace = 0.6, top = 0.85)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that 97% of our data are in Mastercard(32%) and Visa(65%);  <br>\nwe have a highest value in discover(~8%) against ~3.5% of Mastercard and Visa and 2.87% in American Express"},{"metadata":{},"cell_type":"markdown","source":"#### Card 6 - Categorical"},{"metadata":{"trusted":false},"cell_type":"code","source":"tmp = pd.crosstab(train_transaction['card6'], train_transaction['isFraud'], normalize='index') * 100\ntmp = tmp.reset_index()\ntmp.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n\nplt.figure(figsize=(14,10))\nplt.suptitle('Card 6 Distributions', fontsize=22)\n\nplt.subplot(221)\ng = sns.countplot(x='card6', data=train_transaction, order=list(tmp.card6.values))\n# plt.legend(title='Fraud', loc='upper center', labels=['No', 'Yes'])\ng.set_title(\"Card6 Distribution\", fontsize=19)\ng.set_ylim(0,480000)\ng.set_xlabel(\"Card6 Category Names\", fontsize=17)\ng.set_ylabel(\"Count\", fontsize=17)\nfor p in g.patches:\n    height = p.get_height()\n    g.text(p.get_x()+p.get_width()/2.,\n            height + 3,\n            '{:1.2f}%'.format(height/total*100),\n            ha=\"center\",fontsize=14) \n\nplt.subplot(222)\ng1 = sns.countplot(x='card6', hue='isFraud', data=train_transaction, order=list(tmp.card6.values))\nplt.legend(title='Fraud', loc='best', labels=['No', 'Yes'])\ngt = g1.twinx()\ngt = sns.pointplot(x='card6', y='Fraud', data=tmp, order=list(tmp.card6.values),\n                   color='black', legend=False, )\ngt.set_ylim(0,20)\ngt.set_ylabel(\"% of Fraud Transactions\", fontsize=16)\ng1.set_title(\"Card6 by Target(isFraud)\", fontsize=19)\ng1.set_xlabel(\"Card6 Category Names\", fontsize=17)\ng1.set_ylabel(\"Count\", fontsize=17)\n\nplt.subplot(212)\ng3 = sns.boxenplot(x='card6', y='TransactionAmt', hue='isFraud', order=list(tmp.card6.values),\n              data=train_transaction[train_transaction['TransactionAmt'] <= 2000] )\ng3.set_title(\"Card 6 Distribuition by ProductCD and Target\", fontsize=20)\ng3.set_xlabel(\"Card6 Category Names\", fontsize=17)\ng3.set_ylabel(\"Transaction Values\", fontsize=17)\n\nplt.subplots_adjust(hspace = 0.6, top = 0.85)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that 97% of our data are in Mastercard(32%) and Visa(65%);  <br>\nwe have a highest value in discover(~8%) against ~3.5% of Mastercard and Visa and 2.87% in American Express"},{"metadata":{},"cell_type":"markdown","source":"Before Ploting the Transaction Amount, let's see the quantiles of Transaction Amount"},{"metadata":{"trusted":false},"cell_type":"code","source":"train_transaction['TransactionAmt'] = train_transaction['TransactionAmt'].astype(float)\nprint(\"Transaction Amounts Quantiles:\")\nprint(train_transaction['TransactionAmt'].quantile([.01, .025, .1, .25, .5, .75, .9, .975, .99]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have 3.5% of Fraud transactions in our dataset. <br>I think that it would be interesting to see if the amount percentual is higher or lower than 3.5% of total. I will see it later. <br>\nWe have the same % when considering the Total Transactions Amount by Fraud and No Fraud. <br>\nLet's explore the Transaction amount further below."},{"metadata":{},"cell_type":"markdown","source":"### Ploting Transaction Amount Values Distribution\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(16,12))\nplt.suptitle('Transaction Values Distribution', fontsize=22)\nplt.subplot(221)\ng = sns.distplot(train_transaction[train_transaction['TransactionAmt'] <= 1000]['TransactionAmt'])\ng.set_title(\"Transaction Amount Distribuition <= 1000\", fontsize=18)\ng.set_xlabel(\"\")\ng.set_ylabel(\"Probability\", fontsize=15)\n\nplt.subplot(222)\ng1 = sns.distplot(np.log(train_transaction['TransactionAmt']))\ng1.set_title(\"Transaction Amount (Log) Distribuition\", fontsize=18)\ng1.set_xlabel(\"\")\ng1.set_ylabel(\"Probability\", fontsize=15)\n\nplt.figure(figsize=(16,12))\n\n\nplt.subplot(212)\ng4 = plt.scatter(range(train_transaction[train_transaction['isFraud'] == 0].shape[0]),\n                 np.sort(train_transaction[train_transaction['isFraud'] == 0]['TransactionAmt'].values), \n                 label='NoFraud', alpha=.2)\ng4 = plt.scatter(range(train_transaction[train_transaction['isFraud'] == 1].shape[0]),\n                 np.sort(train_transaction[train_transaction['isFraud'] == 1]['TransactionAmt'].values), \n                 label='Fraud', alpha=.2)\ng4= plt.title(\"ECDF \\nFRAUD and NO FRAUD Transaction Amount Distribution\", fontsize=18)\ng4 = plt.xlabel(\"Index\")\ng4 = plt.ylabel(\"Amount Distribution\", fontsize=15)\ng4 = plt.legend()\n\nplt.figure(figsize=(16,12))\n\nplt.subplot(321)\ng = plt.scatter(range(train_transaction[train_transaction['isFraud'] == 1].shape[0]), \n                 np.sort(train_transaction[train_transaction['isFraud'] == 1]['TransactionAmt'].values), \n                label='isFraud', alpha=.4)\nplt.title(\"FRAUD - Transaction Amount ECDF\", fontsize=18)\nplt.xlabel(\"Index\")\nplt.ylabel(\"Amount Distribution\", fontsize=12)\n\nplt.subplot(322)\ng1 = plt.scatter(range(train_transaction[train_transaction['isFraud'] == 0].shape[0]),\n                 np.sort(train_transaction[train_transaction['isFraud'] == 0]['TransactionAmt'].values), \n                 label='NoFraud', alpha=.2)\ng1= plt.title(\"NO FRAUD - Transaction Amount ECDF\", fontsize=18)\ng1 = plt.xlabel(\"Index\")\ng1 = plt.ylabel(\"Amount Distribution\", fontsize=15)\n\nplt.suptitle('Individual ECDF Distribution', fontsize=22)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Seeing the Quantiles of Fraud and No Fraud Transactions"},{"metadata":{"trusted":false},"cell_type":"code","source":"print(pd.concat([train_transaction[train_transaction['isFraud'] == 1]['TransactionAmt']\\\n                 .quantile([.01, .1, .25, .5, .75, .9, .99])\\\n                 .reset_index(), \n                 train_transaction[train_transaction['isFraud'] == 0]['TransactionAmt']\\\n                 .quantile([.01, .1, .25, .5, .75, .9, .99])\\\n                 .reset_index()],\n                axis=1, keys=['Fraud', \"No Fraud\"]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Transaction Amount Outliers\n- It's considering outlier values that are highest than 3 times the std from the mean\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"CalcOutliers(train_transaction['TransactionAmt'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Now, let's known the Product Feature\n- Distribution Products\n- Distribution of Frauds by Product\n- Has Difference between Transaction Amounts in Products? "},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"tmp = pd.crosstab(train_transaction['ProductCD'], train_transaction['isFraud'], normalize='index') * 100\ntmp = tmp.reset_index()\ntmp.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n\nplt.figure(figsize=(14,10))\nplt.suptitle('ProductCD Distributions', fontsize=22)\n\nplt.subplot(221)\ng = sns.countplot(x='ProductCD', data=train_transaction)\n# plt.legend(title='Fraud', loc='upper center', labels=['No', 'Yes'])\n\ng.set_title(\"ProductCD Distribution\", fontsize=19)\ng.set_xlabel(\"ProductCD Name\", fontsize=17)\ng.set_ylabel(\"Count\", fontsize=17)\ng.set_ylim(0,500000)\nfor p in g.patches:\n    height = p.get_height()\n    g.text(p.get_x()+p.get_width()/2.,\n            height + 3,\n            '{:1.2f}%'.format(height/total*100),\n            ha=\"center\", fontsize=14) \n\nplt.subplot(222)\ng1 = sns.countplot(x='ProductCD', hue='isFraud', data=train_transaction)\nplt.legend(title='Fraud', loc='best', labels=['No', 'Yes'])\ngt = g1.twinx()\ngt = sns.pointplot(x='ProductCD', y='Fraud', data=tmp, color='black', order=['W', 'H',\"C\", \"S\", \"R\"], legend=False)\ngt.set_ylabel(\"% of Fraud Transactions\", fontsize=16)\n\ng1.set_title(\"Product CD by Target(isFraud)\", fontsize=19)\ng1.set_xlabel(\"ProductCD Name\", fontsize=17)\ng1.set_ylabel(\"Count\", fontsize=17)\n\nplt.subplot(212)\ng3 = sns.boxenplot(x='ProductCD', y='TransactionAmt', hue='isFraud', \n              data=train_transaction[train_transaction['TransactionAmt'] <= 2000] )\ng3.set_title(\"Transaction Amount Distribuition by ProductCD and Target\", fontsize=20)\ng3.set_xlabel(\"ProductCD Name\", fontsize=17)\ng3.set_ylabel(\"Transaction Values\", fontsize=17)\n\nplt.subplots_adjust(hspace = 0.6, top = 0.85)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploring M1-M9 Features "},{"metadata":{"trusted":false},"cell_type":"code","source":"for col in ['M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9']:\n    train_transaction[col] = train_transaction[col].fillna(\"Miss\")\n    \ndef ploting_dist_ratio(df, col, lim=2000):\n    tmp = pd.crosstab(df[col], df['isFraud'], normalize='index') * 100\n    tmp = tmp.reset_index()\n    tmp.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n\n    plt.figure(figsize=(20,5))\n    plt.suptitle(f'{col} Distributions ', fontsize=22)\n\n    plt.subplot(121)\n    g = sns.countplot(x=col, data=df, order=list(tmp[col].values))\n    # plt.legend(title='Fraud', loc='upper center', labels=['No', 'Yes'])\n    g.set_title(f\"{col} Distribution\\nCound and %Fraud by each category\", fontsize=18)\n    g.set_ylim(0,400000)\n    gt = g.twinx()\n    gt = sns.pointplot(x=col, y='Fraud', data=tmp, order=list(tmp[col].values),\n                       color='black', legend=False, )\n    gt.set_ylim(0,20)\n    gt.set_ylabel(\"% of Fraud Transactions\", fontsize=16)\n    g.set_xlabel(f\"{col} Category Names\", fontsize=16)\n    g.set_ylabel(\"Count\", fontsize=17)\n    for p in gt.patches:\n        height = p.get_height()\n        gt.text(p.get_x()+p.get_width()/2.,\n                height + 3,\n                '{:1.2f}%'.format(height/total*100),\n                ha=\"center\",fontsize=14) \n        \n    perc_amt = (train_transaction.groupby(['isFraud',col])['TransactionAmt'].sum() / total_amt * 100).unstack('isFraud')\n    perc_amt = perc_amt.reset_index()\n    perc_amt.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n\n    plt.subplot(122)\n    g1 = sns.boxplot(x=col, y='TransactionAmt', hue='isFraud', \n                     data=df[df['TransactionAmt'] <= lim], order=list(tmp[col].values))\n    g1t = g1.twinx()\n    g1t = sns.pointplot(x=col, y='Fraud', data=perc_amt, order=list(tmp[col].values),\n                       color='black', legend=False, )\n    g1t.set_ylim(0,5)\n    g1t.set_ylabel(\"%Fraud Total Amount\", fontsize=16)\n    g1.set_title(f\"{col} by Transactions dist\", fontsize=18)\n    g1.set_xlabel(f\"{col} Category Names\", fontsize=16)\n    g1.set_ylabel(\"Transaction Amount(U$)\", fontsize=16)\n        \n    plt.subplots_adjust(hspace=.4, wspace = 0.35, top = 0.80)\n    \n    plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### M distributions:  Count, %Fraud and Transaction Amount distribution"},{"metadata":{"trusted":false},"cell_type":"code","source":"for col in ['M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9']:\n    ploting_dist_ratio(train_transaction, col, lim=2500)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Very cool!!! This graphs give us many interesting intuition about the M features.<br>\nOnly in M4 the Missing values haven't the highest % of Fraud.\n\n"},{"metadata":{},"cell_type":"markdown","source":"## Addr1 and Addr2"},{"metadata":{"trusted":false},"cell_type":"code","source":"print(\"Card Features Quantiles: \")\nprint(train_transaction[['addr1', 'addr2']].quantile([0.01, .025, .1, .25, .5, .75, .90,.975, .99]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I will set all values in Addr1 that has less than 5000 entries to \"Others\"<br>\nIn Addr2 I will set as \"Others\" all values with less than 50 entries"},{"metadata":{"trusted":false},"cell_type":"code","source":"train_transaction.loc[train_transaction.addr1.isin(train_transaction.addr1.value_counts()[train_transaction.addr1.value_counts() <= 5000 ].index), 'addr1'] = \"Others\"\ntrain_transaction.loc[train_transaction.addr2.isin(train_transaction.addr2.value_counts()[train_transaction.addr2.value_counts() <= 50 ].index), 'addr2'] = \"Others\"    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Addr1 Distributions"},{"metadata":{"trusted":false},"cell_type":"code","source":" def ploting_cnt_amt(df, col, lim=2000):\n    tmp = pd.crosstab(df[col], df['isFraud'], normalize='index') * 100\n    tmp = tmp.reset_index()\n    tmp.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n    \n    plt.figure(figsize=(16,14))    \n    plt.suptitle(f'{col} Distributions ', fontsize=24)\n    \n    plt.subplot(211)\n    g = sns.countplot( x=col,  data=df, order=list(tmp[col].values))\n    gt = g.twinx()\n    gt = sns.pointplot(x=col, y='Fraud', data=tmp, order=list(tmp[col].values),\n                       color='black', legend=False, )\n    gt.set_ylim(0,tmp['Fraud'].max()*1.1)\n    gt.set_ylabel(\"%Fraud Transactions\", fontsize=16)\n    g.set_title(f\"Most Frequent {col} values and % Fraud Transactions\", fontsize=20)\n    g.set_xlabel(f\"{col} Category Names\", fontsize=16)\n    g.set_ylabel(\"Count\", fontsize=17)\n    g.set_xticklabels(g.get_xticklabels(),rotation=45)\n    sizes = []\n    for p in g.patches:\n        height = p.get_height()\n        sizes.append(height)\n        g.text(p.get_x()+p.get_width()/2.,\n                height + 3,\n                '{:1.2f}%'.format(height/total*100),\n                ha=\"center\",fontsize=12) \n        \n    g.set_ylim(0,max(sizes)*1.15)\n    \n    #########################################################################\n    perc_amt = (df.groupby(['isFraud',col])['TransactionAmt'].sum() \\\n                / df.groupby([col])['TransactionAmt'].sum() * 100).unstack('isFraud')\n    perc_amt = perc_amt.reset_index()\n    perc_amt.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n    amt = df.groupby([col])['TransactionAmt'].sum().reset_index()\n    perc_amt = perc_amt.fillna(0)\n    plt.subplot(212)\n    g1 = sns.barplot(x=col, y='TransactionAmt', \n                       data=amt, \n                       order=list(tmp[col].values))\n    g1t = g1.twinx()\n    g1t = sns.pointplot(x=col, y='Fraud', data=perc_amt, \n                        order=list(tmp[col].values),\n                       color='black', legend=False, )\n    g1t.set_ylim(0,perc_amt['Fraud'].max()*1.1)\n    g1t.set_ylabel(\"%Fraud Total Amount\", fontsize=16)\n    g.set_xticklabels(g.get_xticklabels(),rotation=45)\n    g1.set_title(f\"{col} by Transactions Total + %of total and %Fraud Transactions\", fontsize=20)\n    g1.set_xlabel(f\"{col} Category Names\", fontsize=16)\n    g1.set_ylabel(\"Transaction Total Amount(U$)\", fontsize=16)\n    g1.set_xticklabels(g.get_xticklabels(),rotation=45)    \n    \n    for p in g1.patches:\n        height = p.get_height()\n        g1.text(p.get_x()+p.get_width()/2.,\n                height + 3,\n                '{:1.2f}%'.format(height/total_amt*100),\n                ha=\"center\",fontsize=12) \n        \n    plt.subplots_adjust(hspace=.4, top = 0.9)\n    plt.show()\n    \nploting_cnt_amt(train_transaction, 'addr1')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can note interesting patterns on Addr1."},{"metadata":{},"cell_type":"markdown","source":"Almost all entries in Addr2 are in the same value. <br>\nInterestingly in the value 65 , the percent of frauds are almost 60% <br>\nAltought the value 87 has 88% of total entries, it has 96% of Total Transaction Amounts"},{"metadata":{"trusted":false},"cell_type":"code","source":"ploting_cnt_amt(train_transaction, 'addr2')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## emaildomain Distributions\n### P emaildomain Distributions\n- I will group all e-mail domains by the respective enterprises.\n- Also, I will set as \"Others\" all values with less than 500 entries."},{"metadata":{"trusted":false},"cell_type":"code","source":"train_transaction.loc[train_transaction['P_emaildomain'].isin(['gmail.com', 'gmail']),'P_emaildomain'] = 'Google'\n\ntrain_transaction.loc[train_transaction['P_emaildomain'].isin(['yahoo.com', 'yahoo.com.mx',  'yahoo.co.uk',\n                                         'yahoo.co.jp', 'yahoo.de', 'yahoo.fr',\n                                         'yahoo.es']), 'P_emaildomain'] = 'Yahoo Mail'\ntrain_transaction.loc[train_transaction['P_emaildomain'].isin(['hotmail.com','outlook.com','msn.com', 'live.com.mx', \n                                         'hotmail.es','hotmail.co.uk', 'hotmail.de',\n                                         'outlook.es', 'live.com', 'live.fr',\n                                         'hotmail.fr']), 'P_emaildomain'] = 'Microsoft'\ntrain_transaction.loc[train_transaction.P_emaildomain.isin(train_transaction.P_emaildomain\\\n                                         .value_counts()[train_transaction.P_emaildomain.value_counts() <= 500 ]\\\n                                         .index), 'P_emaildomain'] = \"Others\"\ntrain_transaction.P_emaildomain.fillna(\"NoInf\", inplace=True)\ntrain_transaction.loc[train_transaction['P_emaildomain'].isin(['gmail.com', 'gmail']),'P_emaildomain'] = 'Google'\n\ntrain_transaction.loc[train_transaction['P_emaildomain'].isin(['yahoo.com', 'yahoo.com.mx',  'yahoo.co.uk',\n                                         'yahoo.co.jp', 'yahoo.de', 'yahoo.fr',\n                                         'yahoo.es']), 'P_emaildomain'] = 'Yahoo Mail'\ntrain_transaction.loc[train_transaction['P_emaildomain'].isin(['hotmail.com','outlook.com','msn.com', 'live.com.mx', \n                                         'hotmail.es','hotmail.co.uk', 'hotmail.de',\n                                         'outlook.es', 'live.com', 'live.fr',\n                                         'hotmail.fr']), 'P_emaildomain'] = 'Microsoft'\ntrain_transaction.loc[train_transaction.P_emaildomain.isin(train_transaction.P_emaildomain\\\n                                         .value_counts()[train_transaction.P_emaildomain.value_counts() <= 500 ]\\\n                                         .index), 'P_emaildomain'] = \"Others\"\ntrain_transaction.P_emaildomain.fillna(\"NoInf\", inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Ploting P-Email Domain"},{"metadata":{"trusted":false},"cell_type":"code","source":"ploting_cnt_amt(train_transaction, 'P_emaildomain')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### R-Email Domain plot distribution\n- I will group all e-mail domains by the respective enterprises.\n- I will set as \"Others\" all values with less than 300 entries."},{"metadata":{"trusted":false},"cell_type":"code","source":"train_transaction.loc[train_transaction['R_emaildomain'].isin(['gmail.com', 'gmail']),'R_emaildomain'] = 'Google'\n\ntrain_transaction.loc[train_transaction['R_emaildomain'].isin(['yahoo.com', 'yahoo.com.mx',  'yahoo.co.uk',\n                                             'yahoo.co.jp', 'yahoo.de', 'yahoo.fr',\n                                             'yahoo.es']), 'R_emaildomain'] = 'Yahoo Mail'\ntrain_transaction.loc[train_transaction['R_emaildomain'].isin(['hotmail.com','outlook.com','msn.com', 'live.com.mx', \n                                             'hotmail.es','hotmail.co.uk', 'hotmail.de',\n                                             'outlook.es', 'live.com', 'live.fr',\n                                             'hotmail.fr']), 'R_emaildomain'] = 'Microsoft'\ntrain_transaction.loc[train_transaction.R_emaildomain.isin(train_transaction.R_emaildomain\\\n                                         .value_counts()[train_transaction.R_emaildomain.value_counts() <= 300 ]\\\n                                         .index), 'R_emaildomain'] = \"Others\"\ntrain_transaction.R_emaildomain.fillna(\"NoInf\", inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ploting_cnt_amt(train_transaction, 'R_emaildomain')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see a very similar distribution in both email domain features. <br>\nIt's interesting that we have high values in google and icloud frauds\n"},{"metadata":{},"cell_type":"markdown","source":"## C1-C14 features\n- Let's understand what this features are.\n- What's the distributions? "},{"metadata":{"trusted":false},"cell_type":"code","source":"resumetable(train_transaction[['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8',\n                      'C9', 'C10', 'C11', 'C12', 'C13', 'C14']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_transaction[['C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8',\n                      'C9', 'C10', 'C11', 'C12', 'C13', 'C14']].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_transaction.loc[train_transaction.C1.isin(train_transaction.C1\\\n                              .value_counts()[train_transaction.C1.value_counts() <= 400 ]\\\n                              .index), 'C1'] = \"Others\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### C1 Distribution Plot"},{"metadata":{"trusted":false},"cell_type":"code","source":"ploting_cnt_amt(train_transaction, 'C1')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### C2 Distribution Plot"},{"metadata":{"trusted":false},"cell_type":"code","source":"train_transaction.loc[train_transaction.C2.isin(train_transaction.C2\\\n                              .value_counts()[train_transaction.C2.value_counts() <= 350 ]\\\n                              .index), 'C2'] = \"Others\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ploting_cnt_amt(train_transaction, 'C2')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## TimeDelta Feature\n- Let's see if the frauds have some specific hour that has highest % of frauds "},{"metadata":{},"cell_type":"markdown","source":"### Converting to Total Days, Weekdays and Hours\nIn discussions tab I read an excellent solution to Timedelta column, I will set the link below; <br>\nWe will use the first date as 2017-12-01 and use the delta time to compute datetime features\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"# https://www.kaggle.com/c/ieee-fraud-detection/discussion/100400#latest-579480\nimport datetime\n\nSTART_DATE = '2017-12-01'\nstartdate = datetime.datetime.strptime(START_DATE, \"%Y-%m-%d\")\ntrain_transaction[\"Date\"] = train_transaction['TransactionDT'].apply(lambda x: (startdate + datetime.timedelta(seconds=x)))\n\ntrain_transaction['_Weekdays'] = train_transaction['Date'].dt.dayofweek\ntrain_transaction['_Hours'] = train_transaction['Date'].dt.hour\ntrain_transaction['_Days'] = train_transaction['Date'].dt.day","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Top Days with highest Total Transaction Amount"},{"metadata":{"trusted":false},"cell_type":"code","source":"ploting_cnt_amt(train_transaction, '_Days')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Ploting WeekDays Distributions"},{"metadata":{"trusted":false},"cell_type":"code","source":"ploting_cnt_amt(train_transaction, '_Weekdays')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We don't have the reference of date but we can see that two days has lower transactions, that we can infer it is weekend days"},{"metadata":{},"cell_type":"markdown","source":"### Ploting Hours Distributions\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"ploting_cnt_amt(train_transaction, '_Hours')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Transactions and Total Amount by each day"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Calling the function to transform the date column in datetime pandas object\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nfrom plotly.offline import iplot, init_notebook_mode\n#seting some static color options\ncolor_op = ['#5527A0', '#BB93D7', '#834CF7', '#6C941E', '#93EAEA', '#7425FF', '#F2098A', '#7E87AC', \n            '#EBE36F', '#7FD394', '#49C35D', '#3058EE', '#44FDCF', '#A38F85', '#C4CEE0', '#B63A05', \n            '#4856BF', '#F0DB1B', '#9FDBD9', '#B123AC']\n\n\ndates_temp = train_transaction.groupby(train_transaction.Date.dt.date)['TransactionAmt'].count().reset_index()\n# renaming the columns to apropriate names\n\n# creating the first trace with the necessary parameters\ntrace = go.Scatter(x=dates_temp['Date'], y=dates_temp.TransactionAmt,\n                    opacity = 0.8, line = dict(color = color_op[7]), name= 'Total Transactions')\n\n# Below we will get the total amount sold\ndates_temp_sum = train_transaction.groupby(train_transaction.Date.dt.date)['TransactionAmt'].sum().reset_index()\n\n# using the new dates_temp_sum we will create the second trace\ntrace1 = go.Scatter(x=dates_temp_sum.Date, line = dict(color = color_op[1]), name=\"Total Amount\",\n                        y=dates_temp_sum['TransactionAmt'], opacity = 0.8, yaxis='y2')\n\n#creating the layout the will allow us to give an title and \n# give us some interesting options to handle with the outputs of graphs\nlayout = dict(\n    title= \"Total Transactions and Fraud Informations by Date\",\n    xaxis=dict(\n        rangeselector=dict(\n            buttons=list([\n                dict(count=1, label='1m', step='month', stepmode='backward'),\n                dict(count=3, label='3m', step='month', stepmode='backward'),\n                dict(count=6, label='6m', step='month', stepmode='backward'),\n                dict(step='all')\n            ])\n        ),\n        rangeslider=dict(visible = True),\n        type='date' ),\n    yaxis=dict(title='Total Transactions'),\n    yaxis2=dict(overlaying='y',\n                anchor='x', side='right',\n                zeroline=False, showgrid=False,\n                title='Total Transaction Amount')\n)\n\n# creating figure with the both traces and layout\nfig = dict(data= [trace, trace1,], layout=layout)\n\n#rendering the graphs\niplot(fig) #it's an equivalent to plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### FRAUD TRANSACTIONS BY DATE\n- Visualizing only Fraud Transactions by Date"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Calling the function to transform the date column in datetime pandas object\n\n#seting some static color options\ncolor_op = ['#5527A0', '#BB93D7', '#834CF7', '#6C941E', '#93EAEA', '#7425FF', '#F2098A', '#7E87AC', \n            '#EBE36F', '#7FD394', '#49C35D', '#3058EE', '#44FDCF', '#A38F85', '#C4CEE0', '#B63A05', \n            '#4856BF', '#F0DB1B', '#9FDBD9', '#B123AC']\n\ntmp_amt = train_transaction.groupby([train_transaction.Date.dt.date, 'isFraud'])['TransactionAmt'].sum().reset_index()\ntmp_trans = train_transaction.groupby([train_transaction.Date.dt.date, 'isFraud'])['TransactionAmt'].count().reset_index()\n\ntmp_trans_fraud = tmp_trans[tmp_trans['isFraud'] == 1]\ntmp_amt_fraud = tmp_amt[tmp_amt['isFraud'] == 1]\n\ndates_temp = train_transaction.groupby(train_transaction.Date.dt.date)['TransactionAmt'].count().reset_index()\n# renaming the columns to apropriate names\n\n# creating the first trace with the necessary parameters\ntrace = go.Scatter(x=tmp_trans_fraud['Date'], y=tmp_trans_fraud.TransactionAmt,\n                    opacity = 0.8, line = dict(color = color_op[1]), name= 'Fraud Transactions')\n\n# using the new dates_temp_sum we will create the second trace\ntrace1 = go.Scatter(x=tmp_amt_fraud.Date, line = dict(color = color_op[7]), name=\"Fraud Amount\",\n                    y=tmp_amt_fraud['TransactionAmt'], opacity = 0.8, yaxis='y2')\n\n#creating the layout the will allow us to give an title and \n# give us some interesting options to handle with the outputs of graphs\nlayout = dict(\n    title= \"FRAUD TRANSACTIONS - Total Transactions and Fraud Informations by Date\",\n    xaxis=dict(\n        rangeselector=dict(\n            buttons=list([\n                dict(count=1, label='1m', step='month', stepmode='backward'),\n                dict(count=3, label='3m', step='month', stepmode='backward'),\n                dict(count=6, label='6m', step='month', stepmode='backward'),\n                dict(step='all')\n            ])\n        ),\n        rangeslider=dict(visible = True),\n        type='date' ),\n    yaxis=dict(title='Total Transactions'),\n    yaxis2=dict(overlaying='y',\n                anchor='x', side='right',\n                zeroline=False, showgrid=False,\n                title='Total Transaction Amount')\n)\n\n# creating figure with the both traces and layout\nfig = dict(data= [trace, trace1], layout=layout)\n\n#rendering the graphs\niplot(fig) #it's an equivalent to plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Features [id_12 to id_38]\n- categorical features in training identity dataset"},{"metadata":{"trusted":false},"cell_type":"code","source":"train_identity[['id_12', 'id_13', 'id_14', 'id_15', 'id_16', 'id_17', 'id_18',\n       'id_19', 'id_20', 'id_21', 'id_22', 'id_23', 'id_24', 'id_25',\n       'id_26', 'id_27', 'id_28', 'id_29', 'id_30', 'id_31', 'id_32',\n       'id_33', 'id_34', 'id_35', 'id_36', 'id_37', 'id_38']].describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_train = train_transaction.merge(train_identity, how='left', left_index=True, right_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def cat_feat_ploting(df, col):\n    tmp = pd.crosstab(df[col], df['isFraud'], normalize='index') * 100\n    tmp = tmp.reset_index()\n    tmp.rename(columns={0:'NoFraud', 1:'Fraud'}, inplace=True)\n\n    plt.figure(figsize=(14,10))\n    plt.suptitle(f'{col} Distributions', fontsize=22)\n\n    plt.subplot(221)\n    g = sns.countplot(x=col, data=df, order=tmp[col].values)\n    # plt.legend(title='Fraud', loc='upper center', labels=['No', 'Yes'])\n\n    g.set_title(f\"{col} Distribution\", fontsize=19)\n    g.set_xlabel(f\"{col} Name\", fontsize=17)\n    g.set_ylabel(\"Count\", fontsize=17)\n    # g.set_ylim(0,500000)\n    for p in g.patches:\n        height = p.get_height()\n        g.text(p.get_x()+p.get_width()/2.,\n                height + 3,\n                '{:1.2f}%'.format(height/total*100),\n                ha=\"center\", fontsize=14) \n\n    plt.subplot(222)\n    g1 = sns.countplot(x=col, hue='isFraud', data=df, order=tmp[col].values)\n    plt.legend(title='Fraud', loc='best', labels=['No', 'Yes'])\n    gt = g1.twinx()\n    gt = sns.pointplot(x=col, y='Fraud', data=tmp, color='black', order=tmp[col].values, legend=False)\n    gt.set_ylabel(\"% of Fraud Transactions\", fontsize=16)\n\n    g1.set_title(f\"{col} by Target(isFraud)\", fontsize=19)\n    g1.set_xlabel(f\"{col} Name\", fontsize=17)\n    g1.set_ylabel(\"Count\", fontsize=17)\n\n    plt.subplot(212)\n    g3 = sns.boxenplot(x=col, y='TransactionAmt', hue='isFraud', \n                       data=df[df['TransactionAmt'] <= 2000], order=tmp[col].values )\n    g3.set_title(\"Transaction Amount Distribuition by ProductCD and Target\", fontsize=20)\n    g3.set_xlabel(\"ProductCD Name\", fontsize=17)\n    g3.set_ylabel(\"Transaction Values\", fontsize=17)\n\n    plt.subplots_adjust(hspace = 0.4, top = 0.85)\n\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Ploting columns with few unique values"},{"metadata":{"trusted":false},"cell_type":"code","source":"for col in ['id_12', 'id_15', 'id_16', 'id_23', 'id_27', 'id_28', 'id_29']:\n    df_train[col] = df_train[col].fillna('NaN')\n    cat_feat_ploting(df_train, col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_train.loc[df_train['id_30'].str.contains('Windows', na=False), 'id_30'] = 'Windows'\ndf_train.loc[df_train['id_30'].str.contains('iOS', na=False), 'id_30'] = 'iOS'\ndf_train.loc[df_train['id_30'].str.contains('Mac OS', na=False), 'id_30'] = 'Mac'\ndf_train.loc[df_train['id_30'].str.contains('Android', na=False), 'id_30'] = 'Android'\ndf_train['id_30'].fillna(\"NAN\", inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_train.loc[df_train['id_31'].str.contains('chrome', na=False), 'id_31'] = 'Chrome'\ndf_train.loc[df_train['id_31'].str.contains('firefox', na=False), 'id_31'] = 'Firefox'\ndf_train.loc[df_train['id_31'].str.contains('safari', na=False), 'id_31'] = 'Safari'\ndf_train.loc[df_train['id_31'].str.contains('edge', na=False), 'id_31'] = 'Edge'\ndf_train.loc[df_train['id_31'].str.contains('ie', na=False), 'id_31'] = 'IE'\ndf_train.loc[df_train['id_31'].str.contains('samsung', na=False), 'id_31'] = 'Samsung'\ndf_train.loc[df_train['id_31'].str.contains('opera', na=False), 'id_31'] = 'Opera'\ndf_train['id_31'].fillna(\"NAN\", inplace=True)\ndf_train.loc[df_train.id_31.isin(df_train.id_31.value_counts()[df_train.id_31.value_counts() < 200].index), 'id_31'] = \"Others\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ploting_cnt_amt(df_train, 'id_31')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.2"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":false,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"768px","left":"10px","top":"150px","width":"219px"},"toc_section_display":true,"toc_window_display":true}},"nbformat":4,"nbformat_minor":1}