{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrapping with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "    \n",
    "def findH2(tag):\n",
    "    return tag.name == 'h2' and 'requirements' in tag.text\n",
    "\n",
    "\n",
    "def parse_table(table):\n",
    "    \"\"\" Get data from table \"\"\"\n",
    "    return [\n",
    "        [cell.get_text().strip() for cell in row.find_all(['th', 'td'])]\n",
    "           for row in table.find_all('tr')\n",
    "    ]\n",
    "\n",
    "def get_table(soup):\n",
    "    h2 = soup.find_all(findH2)\n",
    "    try:\n",
    "        h2 = soup.find_all(findH2)\n",
    "        table = sibling.find_next('table')\n",
    "    except AttributeError as e:\n",
    "        print('No tables found, exiting')\n",
    "        return 1\n",
    "    \n",
    "    return table\n",
    "\n",
    "\n",
    "domain = 'https://en.wikipedia.org'\n",
    "url = domain+\"/w/index.php?title=Category:Visa_requirements_by_nationality\";\n",
    "\n",
    "result = requests.get(url)\n",
    "\n",
    "result.status_code\n",
    "c = result.content\n",
    "soup = BeautifulSoup(c)\n",
    "\n",
    "samples = soup.find_all(\"a\", href=re.compile(\"Visa_requirements_for\"))\n",
    "\n",
    "i = 0\n",
    "for a in samples:\n",
    "    link = a.get('href')\n",
    "    if i == 9:\n",
    "        break\n",
    "    i +=1\n",
    "    \n",
    "    \n",
    "url = domain+link;\n",
    "\n",
    "print(url)\n",
    "result = requests.get(url)\n",
    "\n",
    "if result.status_code:\n",
    "    c = result.content\n",
    "    soup = BeautifulSoup(c)\n",
    "\n",
    "    soup = BeautifulSoup(html3)\n",
    "\n",
    "    table = get_table(soup)\n",
    "    table_data = parse_table(table)\n",
    "\n",
    "    i = 0\n",
    "    data = []\n",
    "\n",
    "    for n in table_data:\n",
    "        \n",
    "        if i == 0:\n",
    "            i +=1\n",
    "            continue\n",
    "        country = {\n",
    "            'country': n[0],\n",
    "            'requirement': n[1],\n",
    "            'allowed_stay': n[2],\n",
    "            'notes': n[3]\n",
    "        }\n",
    "        data.append(country)\n",
    "    \n",
    "for n in data:\n",
    "    print(n.get('requirement'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "from influxdb import DataFrameClient\n",
    "from pandas.io.json import json_normalize\n",
    "from pymongo import MongoClient\n",
    "from odo import odo\n",
    "client = MongoClient()\n",
    "\n",
    "mydb = client['stock']\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "def get_client(dbname, host='localhost', port=8086):\n",
    "    \"\"\"Instantiate the connection to the InfluxDB client.\"\"\"\n",
    "    user = 'root'\n",
    "    password = 'root'\n",
    "    \n",
    "    influx = DataFrameClient(host, port, user, password, dbname)\n",
    "    influx.create_database(dbname)\n",
    "    return influx\n",
    "\n",
    "def main(df, metric, dbname, timecolumn, tagcolumn=None, host='localhost', port=8086):\n",
    "    protocol = 'json'\n",
    "    df.set_index(timecolumn,inplace=True)\n",
    "    influx = get_client(dbname)\n",
    "    chunk_size = 500\n",
    "    for start in range(0, df.shape[0], chunk_size):\n",
    "        df_subset = df.iloc[start:start + chunk_size]\n",
    "        influx.write_points(df_subset, coll, protocol=protocol, time_precision='s')\n",
    "    return \n",
    "    \n",
    "\n",
    "\n",
    "influx.drop_database('stocks')\n",
    "    \n",
    "coll = 'historical_day'\n",
    "df = pd.DataFrame(list(mydb[coll].find()))\n",
    "del df['_cls']\n",
    "del df['_id']\n",
    "\n",
    "df.open = df.open*1.00\n",
    "display(df.shape)\n",
    "df = main(df, coll,'stocks','datetime')\n",
    "\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mongoexport --db stock --collection historical_minute --type=csv --fields=tradingsymbol,high,open,datetime,volume,instrument_type,close,low,exchange,instrument_token --out historical_minute.csv\n",
    "# mongoexport --db stock --collection historical_day --type=csv --fields=datetime,close,volume,instrument_type,open,high,tradingsymbol,low,exchange --out historical_day.csv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "\n",
    "df = pd.read_csv(\"historical_minute.csv\", chunksize=500000)\n",
    "measurement='historical_minute'\n",
    "\n",
    "ddl = \"\"\"# DDL\n",
    "CREATE DATABASE stocks\n",
    "\n",
    "# DML\n",
    "# CONTEXT-DATABASE: stocks\n",
    "# CONTEXT-RETENTION-POLICY: autogen\n",
    "\"\"\"\n",
    "with open(measurement+'.txt', 'w') as f:\n",
    "    f.write(\"%s\\n\" % ddl)\n",
    "\n",
    "\n",
    "for chunk in df:\n",
    "    t0 = time()\n",
    "    chunk.high = chunk.high*1.00\n",
    "    chunk.close = chunk.close*1.00\n",
    "    chunk.low = chunk.low*1.00\n",
    "    chunk.volume = chunk.volume*1.00\n",
    "    chunk.datetime = pd.to_datetime(chunk.datetime).astype(int)\n",
    "    timeMulti = time() - t0\n",
    "    lines = []\n",
    "    t1 = time()\n",
    "    \n",
    "    lines = [f'{measurement},instrument_token={row[7]}i close={row[2]},high={row[3]},low={row[4]},instrument_type=\"{row[5]}\",exchange=\"{row[6]}\",tradingsymbol=\"{row[0]}\",open={row[8]},volume={row[9]} {row[10]}' \n",
    "    for row in chunk[[\"tradingsymbol\",\"datetime\",\"close\",\"high\",\"low\",\"instrument_type\",\"exchange\",\"instrument_token\",\"open\",\"volume\",\"datetime\"]].values]\n",
    "    t2 = time()\n",
    "    timeLoop = time() - t1\n",
    "    t3 = time()\n",
    "    with open(measurement+'.txt', 'a') as f:\n",
    "        for item in lines:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "    timeFile = time() - t2\n",
    "    print(\"txt file writing timeMulti: {}, Loop: {},  full: {} write: {}\".format(timeMulti,timeLoop,  time() - t0, timeFile))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -ltrh historical_minute.txt\n",
    "!head historical_minute.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "\n",
    "df=pd.DataFrame( np.random.randn(10000,3), columns=['v','h','l'] )\n",
    "\n",
    "df['vwap_pandas'] = (df.v*(df.h+df.l)/2).cumsum() / df.v.cumsum()\n",
    "\n",
    "@jit\n",
    "def vwap():\n",
    "    tmp1 = np.zeros_like(v)\n",
    "    tmp2 = np.zeros_like(v)\n",
    "    for i in range(0,len(v)):\n",
    "        tmp1[i] = tmp1[i-1] + v[i] * ( h[i] + l[i] ) / 2.\n",
    "        tmp2[i] = tmp2[i-1] + v[i]\n",
    "    return tmp1 / tmp2\n",
    "\n",
    "@jit\n",
    "def np_vwap():\n",
    "    return np.cumsum(v*(h+l)/2) / np.cumsum(v)\n",
    "\n",
    "v = df.v.values\n",
    "h = df.h.values\n",
    "l = df.l.values\n",
    "\n",
    "df['vwap_numpy'] = np.cumsum(v*(h+l)/2) / np.cumsum(v)\n",
    "\n",
    "df['vwap_numba'] = vwap()\n",
    "\n",
    "df['vwap_np_numba'] = np_vwap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "613 µs ± 12.8 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "98.3 µs ± 766 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "38 µs ± 548 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "41.8 µs ± 536 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit (df.v*(df.h+df.l)/2).cumsum() / df.v.cumsum()  # pandas\n",
    "\n",
    "%timeit np.cumsum(v*(h+l)/2) / np.cumsum(v)            # numpy\n",
    "\n",
    "%timeit vwap()                                         # numba\n",
    "\n",
    "%timeit np_vwap()                                         # numba"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
