{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'optuna'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f129eb3d973d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'optuna'"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines.common.policies import MlpLnLstmPolicy\n",
    "from stable_baselines.common.vec_env import SubprocVecEnv, DummyVecEnv\n",
    "from stable_baselines import A2C, ACKTR, PPO2\n",
    "\n",
    "from env.TradingEnv import TradingEnv\n",
    "from util.indicators import add_indicators\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optuna' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-4fa9ac1a7c24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m study = optuna.load_study(study_name='ppo2_calmar',\n\u001b[0m\u001b[1;32m      2\u001b[0m                           storage='sqlite:///params.db')\n\u001b[1;32m      3\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training PPO2 agent with params:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'optuna' is not defined"
     ]
    }
   ],
   "source": [
    "study = optuna.load_study(study_name='ppo2_calmar',\n",
    "                          storage='sqlite:///params.db')\n",
    "params = study.best_trial.params\n",
    "\n",
    "print(\"Training PPO2 agent with params:\", params)\n",
    "print(\"Best trial:\", study.best_trial.value)\n",
    "\n",
    "df = pd.read_csv('./data/coinbase_hourly.csv')\n",
    "df = df.drop(['Symbol'], axis=1)\n",
    "df = df.sort_values(['Date'])\n",
    "df = add_indicators(df.reset_index())\n",
    "\n",
    "test_len = int(len(df) * 0.2)\n",
    "train_len = int(len(df)) - test_len\n",
    "\n",
    "train_df = df[:train_len]\n",
    "test_df = df[train_len:]\n",
    "\n",
    "train_env = DummyVecEnv([lambda: TradingEnv(\n",
    "    train_df, reward_func=\"calmar\", forecast_len=int(params['forecast_len']), confidence_interval=params['confidence_interval'])])\n",
    "\n",
    "test_env = DummyVecEnv([lambda: TradingEnv(\n",
    "    test_df, reward_func=\"calmar\", forecast_len=int(params['forecast_len']), confidence_interval=params['confidence_interval'])])\n",
    "\n",
    "model_params = {\n",
    "    'n_steps': int(params['n_steps']),\n",
    "    'gamma': params['gamma'],\n",
    "    'learning_rate': params['learning_rate'],\n",
    "    'ent_coef': params['ent_coef'],\n",
    "    'cliprange': params['cliprange'],\n",
    "    'noptepochs': int(params['noptepochs']),\n",
    "    'lam': params['lam'],\n",
    "}\n",
    "\n",
    "curr_idx = -1\n",
    "model = PPO2(MlpLnLstmPolicy, train_env, verbose=0, nminibatches=1,\n",
    "            tensorboard_log=\"./tensorboard\", **model_params)\n",
    "\n",
    "# curr_idx = 2\n",
    "# model = PPO2.load('./agents/ppo2_calmar_' + str(curr_idx) + '.pkl', env=train_env)\n",
    "\n",
    "for idx in range(curr_idx + 1, 5):\n",
    "    print('[', idx, '] Training for: ', train_len, ' time steps')\n",
    "\n",
    "    model.learn(total_timesteps=train_len)\n",
    "\n",
    "    obs = test_env.reset()\n",
    "    done, reward_sum = False, 0\n",
    "\n",
    "    while not done:\n",
    "        action, _states = model.predict(obs)\n",
    "        obs, reward, done, info = test_env.step(action)\n",
    "        reward_sum += reward\n",
    "\n",
    "    print('[', idx, '] Total reward: ', reward_sum, ' (calmar)')\n",
    "    model.save('./agents/ppo2_calmar_' + str(idx) + '.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
